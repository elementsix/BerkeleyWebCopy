<!DOCTYPE html>
<!--==============================================================================
	           "GitHub HTML5 Pandoc Template" v1.2 — by Tristano Ajmone           
	==============================================================================
	(c) Tristano Ajmone, 2017, MIT License (MIT). Project's home repository:

	- https://github.com/tajmone/pandoc-goodies

	This template reuses source code taken from the following projects:

	- GitHub Markdown CSS: © Sindre Sorhus, MIT License (MIT):
	  https://github.com/sindresorhus/github-markdown-css

	- Primer CSS: © 2016 GitHub Inc., MIT License (MIT):
	  http://primercss.io/
	==============================================================================-->
<html>

<!-- Mirrored from www.eecs70.org/static/notes/n15.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 17 May 2018 00:40:16 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Two Killer Applications</title>
<style type="text/css">@font-face{font-family:octicons-link;src:url(data:font/woff;charset=utf-8;base64,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) format('woff')}.markdown-body{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;color:#24292e;font-family:-apple-system,system-ui,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";font-size:16px;line-height:1.5;word-wrap:break-word;box-sizing:border-box;min-width:200px;max-width:980px;margin:0 auto;padding:45px}.markdown-body .octicon{display:inline-block;fill:currentColor;vertical-align:text-bottom}.markdown-body a{background-color:transparent;-webkit-text-decoration-skip:objects;color:#0366d6;text-decoration:none}.markdown-body a:active,.markdown-body a:hover{outline-width:0}.markdown-body h1{margin:.67em 0}.markdown-body img{border-style:none}.markdown-body svg:not(:root){overflow:hidden}.markdown-body code,.markdown-body kbd,.markdown-body pre{font-family:monospace,monospace}.markdown-body input{font:inherit;margin:0;overflow:visible;font-family:inherit;font-size:inherit;line-height:inherit}.markdown-body [type=checkbox]{box-sizing:border-box;padding:0}.markdown-body *{box-sizing:border-box}.markdown-body a:hover{text-decoration:underline}.markdown-body strong{font-weight:600}.markdown-body hr{box-sizing:content-box;overflow:hidden;background:0 0;border-bottom:1px solid #dfe2e5}.markdown-body hr::before{display:table;content:""}.markdown-body hr::after{display:table;clear:both;content:""}.markdown-body table{border-spacing:0;border-collapse:collapse;display:block;width:100%;overflow:auto}.markdown-body td,.markdown-body th{padding:0}.markdown-body blockquote{margin:0}.markdown-body ol ol,.markdown-body ul ol{list-style-type:lower-roman}.markdown-body ol ol ol,.markdown-body ol ul ol,.markdown-body ul ol ol,.markdown-body ul ul ol{list-style-type:lower-alpha}.markdown-body dd{margin-left:0}.markdown-body code{font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace}.markdown-body pre{font:12px SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;word-wrap:normal}.markdown-body .pl-0{padding-left:0!important}.markdown-body .pl-1{padding-left:4px!important}.markdown-body .pl-2{padding-left:8px!important}.markdown-body .pl-3{padding-left:16px!important}.markdown-body .pl-4{padding-left:24px!important}.markdown-body .pl-5{padding-left:32px!important}.markdown-body .pl-6{padding-left:40px!important}.markdown-body::before{display:table;content:""}.markdown-body::after{display:table;clear:both;content:""}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .anchor{float:left;padding-right:4px;margin-left:-20px;line-height:1}.markdown-body .anchor:focus{outline:0}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;padding:0;margin:24px 0;background-color:#e1e4e8;border:0}.markdown-body blockquote{padding:0 1em;color:#6a737d;border-left:.25em solid #dfe2e5}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd{font-size:11px;box-shadow:inset 0 -1px 0 #959da5}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#1b1f23;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1{padding-bottom:.3em;font-size:2em;border-bottom:1px solid #eaecef}.markdown-body h2{padding-bottom:.3em;font-size:1.5em;border-bottom:1px solid #eaecef}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#6a737d}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body table th{font-weight:600}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #dfe2e5}.markdown-body table tr{background-color:#fff;border-top:1px solid #c6cbd1}.markdown-body table tr:nth-child(2n){background-color:#f6f8fa}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body code{padding:.2em 0;margin:0;font-size:85%;background-color:rgba(27,31,35,.05);border-radius:3px}.markdown-body code::after,.markdown-body code::before{letter-spacing:-.2em;content:"\00a0"}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:0 0;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:85%;line-height:1.45;background-color:#f6f8fa;border-radius:3px}.markdown-body pre code{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code::after,.markdown-body pre code::before{content:normal}.markdown-body .full-commit .btn-outline:not(:disabled):hover{color:#005cc5;border-color:#005cc5}.markdown-body kbd{display:inline-block;padding:3px 5px;font:11px SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fcfcfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}.markdown-body :checked+.radio-label{position:relative;z-index:1;border-color:#0366d6}.markdown-body .task-list-item{list-style-type:none}.markdown-body .task-list-item+.task-list-item{margin-top:3px}.markdown-body .task-list-item input{margin:0 .2em .25em -1.6em;vertical-align:middle}.markdown-body hr{border-bottom-color:#eee}.flash{position:relative;padding:16px;color:#246;background-color:#e2eef9;border:1px solid #bac6d3;border-radius:3px}.flash p:last-child{margin-bottom:0}.flash-messages{margin-bottom:24px}.flash-warn{color:#4c4a42;background-color:#fff9ea;border-color:#dfd8c2}.flash-error{color:#911;background-color:#fcdede;border-color:#d2b2b2}.flash-success{color:#22662c;background-color:#e2f9e5;border-color:#bad3be}.flash-plain{color:#4c4a42;background-color:#f5f5f5;border-color:#c1c1c1}.figure{text-align:center;}</style>
  <style type="text/css">code{white-space: pre;}</style>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {equationNumbers: {autoNumber: "AMS"}}
    });
  </script>
  <script src="../../../cdn.mathjax.org/mathjax/latest/MathJax2ba6.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  
</head>
<body>
<article class="markdown-body">
<header>
<h1 class="title">Two Killer Applications</h1>
</header>
<nav id="TOC">
<ul>
<li><a href="#two-killer-applications-hashing-and-load-balancing">Two Killer Applications: Hashing and Load Balancing</a><ul>
<li><a href="#balls-and-bins">Balls and Bins</a></li>
<li><a href="#using-the-union-bound">Using the Union Bound</a></li>
<li><a href="#birthday-paradox">Birthday Paradox</a></li>
</ul></li>
<li><a href="#application-2-load-balancing">Application 2: Load Balancing</a><ul>
<li><a href="#back-to-balls-and-bins">Back to Balls and Bins</a></li>
<li><a href="#applying-the-union-bound">Applying the Union Bound</a></li>
</ul></li>
<li><a href="#more-about-hashing-optional">More about Hashing (Optional)</a><ul>
<li><a href="#main-idea">Main Idea</a></li>
<li><a href="#further-simplification">Further Simplification</a></li>
<li><a href="#why-half">Why <span class="math inline">\(1/2\)</span>?</a></li>
</ul></li>
<li><a href="#more-about-load-balancing-optional">More about Load Balancing (Optional)</a></li>
</ul>
</nav>
<h1 id="two-killer-applications-hashing-and-load-balancing" class="unnumbered">Two Killer Applications: Hashing and Load Balancing</h1>
<p>In this lecture we will see that the simple balls-and-bins process can be used to model a surprising range of phenomena. Recall that in this process we distribute <span class="math inline">\(k\)</span> balls in <span class="math inline">\(n\)</span> bins, where each ball is independently placed in a uniformly random bin. We can ask questions such as:</p>
<ul>
<li><p>How large can we choose <span class="math inline">\(k\)</span> while ensuring that with probability at least <span class="math inline">\(1/2\)</span>, no two balls land in the same bin?</p></li>
<li><p>If <span class="math inline">\(k = n\)</span>, what is the maximum number of balls that are likely to land in the same bin?</p></li>
</ul>
<p>As we shall see, these two simple questions provide important insights into two important computer science applications: hashing and load balancing. Our answers to these two questions are based on the application of a simple technique called the union bound, which states that <span class="math inline">\({\mathbb{P}}[A \cup B] \leq {\mathbb{P}}[A] + {\mathbb{P}}[B]\)</span>.</p>
<p>One of the basic issues in hashing is the tradeoff between the size of the hash table and the number of collisions. Here is a simple question that quantifies the tradeoff:</p>
<ul>
<li>Suppose a hash function distributes keys evenly over a table of size <span class="math inline">\(n\)</span>. How many keys can we hash before the probability of a collision exceeds (say) <span class="math inline">\(1/2\)</span>?</li>
</ul>
<p>Recall that a hash table is a data structure that supports the storage of a set of keys drawn from a large universe <span class="math inline">\(U\)</span> (say, the names of all people in the US). The set of keys to be stored changes over time, and so the data structure allows keys to be added and deleted quickly. It also rapidly answers given a key whether it is an element in the currently stored set. The crucial question is how large must the hash table be to allow these operations (addition, deletion and membership) to be implemented quickly.</p>
<p>Here is how the hashing works. The hash function <span class="math inline">\(h\)</span> maps <span class="math inline">\(U\)</span> to a table <span class="math inline">\(T\)</span> of modest size. To <span>add</span> a key <span class="math inline">\(x\)</span> to our set, we evaluate <span class="math inline">\(h(x)\)</span> (i.e., apply the hash function to the key) and store <span class="math inline">\(x\)</span> at the location <span class="math inline">\(h(x)\)</span> in the table <span class="math inline">\(T\)</span>. All keys in our set that are mapped to the same table location are stored in a simple linked list. The operations <span>delete</span> and <span>member</span> are implemented in similar fashion, by evaluating <span class="math inline">\(h(x)\)</span> and searching the linked list at <span class="math inline">\(h(x)\)</span>. Note that the efficiency of a hash function depends on having only few — i.e., keys that map to the same location. This is because the search time for <span>delete</span> and <span>member</span> operations is proportional to the length of the corresponding linked list.</p>
<p>Of course, we could be unlucky and choose keys such that our hash function maps many of them to the same location in the table. But the whole idea behind hashing is that we select our hash function carefully, so that it scrambles up the input key and seems to map it to a random location in the table, making it unlikely that most of the keys we select are mapped to the same location. To quantitatively understand this phenomenon, we will model our hash function as a random function - one that maps each key to a uniformly random location in the table, independently of where all other keys are mapped. The question we will answer is the following: what is the largest number, <span class="math inline">\(m\)</span>, of keys we can store before the probability of a collision reaches <span class="math inline">\(1/2\)</span>? Note that there is nothing special about <span class="math inline">\(1/2\)</span>. One can ask, and answer, the same question with different values of collision probability, and the largest number of keys <span class="math inline">\(m\)</span> will change accordingly.</p>
<h2 id="balls-and-bins" class="unnumbered">Balls and Bins</h2>
<p>Let’s begin by seeing how this problem can be put into the balls and bins framework. The balls will be the <span class="math inline">\(m\)</span> keys to be stored, and the bins will be the <span class="math inline">\(n\)</span> locations in the hash table <span class="math inline">\(T\)</span>. Since the hash function maps each key to a random location in the table <span class="math inline">\(T\)</span>, we can see each key (ball) as choosing a hash table location (bin) uniformly and independently from <span class="math inline">\(T\)</span>. Thus the probability space corresponding to this hashing experiment is exactly the same as the balls and bins space.</p>
<p>We are interested in the event <span class="math inline">\(A\)</span> that there is no collision, or equivalently, that all <span class="math inline">\(m\)</span> balls land in different bins. Clearly <span class="math inline">\({\mathbb{P}}[A]\)</span> will decrease as <span class="math inline">\(m\)</span> increases (with <span class="math inline">\(n\)</span> fixed). Our goal is to find the largest value of <span class="math inline">\(m\)</span> such that <span class="math inline">\({\mathbb{P}}[A]\)</span> remains above <span class="math inline">\(1/2\)</span>. [Note: Really we are looking at different sample spaces here, one for each value of <span class="math inline">\(m\)</span>. So it would be more correct to write <span class="math inline">\({\mathbb{P}}_m\)</span> rather than just <span class="math inline">\({\mathbb{P}}\)</span>, to make clear which sample space we are talking about. However, we will omit this detail.]</p>
<h2 id="using-the-union-bound" class="unnumbered">Using the Union Bound</h2>
<p>Let us see how to use the union bound to achieve this goal. We will fix the value of <span class="math inline">\(m\)</span> and try to compute <span class="math inline">\({\mathbb{P}}[A]\)</span>. There are exactly <span class="math inline">\(k={m\choose 2}=m(m-1)/2\)</span> possible pairs among our <span class="math inline">\(m\)</span> keys. Imagine these are numbered from <span class="math inline">\(1\)</span> to <span class="math inline">\({m\choose 2}\)</span> (it doesn’t matter how). Let <span class="math inline">\(A_i\)</span> denote the event that pair <span class="math inline">\(i\)</span> has a collision (i.e., both keys in the pair are hashed to the same location). Then the event <span class="math inline">\(\overline A\)</span> that <span><em>some</em></span> collision occurs can be written <span class="math inline">\(\overline{A}=\bigcup_{i=1}^k A_i\)</span>. What is <span class="math inline">\({\mathbb{P}}[A_i]\)</span>? We claim it is just <span class="math inline">\(1/n\)</span> for every <span class="math inline">\(i\)</span>; this is just the probability that two particular balls land in the same bin.</p>
<p>So, using the union bound from the last lecture, we have <span class="math display">\[{\mathbb{P}}[\overline{A}] \le \sum_{i=1}^k{\mathbb{P}}[A_i] = k\times{1\over n} = 
                          {{m(m-1)}\over{2n}}\approx{{m^2}\over{2n}}.\]</span> This means that the probability of having a collision is less than <span class="math inline">\(1/2\)</span> provided <span class="math inline">\(m^2/(2n)\le 1/2\)</span>, i.e., provided <span class="math inline">\(m\le\sqrt{n}\)</span>. Thus, if we wish to suffer no collisions, the size of the hash table must be about the square of the cardinality of the set we are trying to store. We will see in the next section on load balancing that the number of collisions does not increase dramatically as we decrease the size of the hash table and make it comparable to the size of the set we are trying to store.</p>
<p>It turns out we can derive a slightly less restrictive bound for <span class="math inline">\(m\)</span> using other techniques from the past several lectures. Although this alternate bound is a little better, both bounds are the same in terms of dependence on <span class="math inline">\(n\)</span> (both are of the form <span class="math inline">\(m = O(\sqrt{n})\)</span>). If you are interested in the alternate derivation, please read the section at the end of this note.</p>
<h2 id="birthday-paradox" class="unnumbered">Birthday Paradox</h2>
<p>Can we do better than the <span class="math inline">\(m = O(\sqrt{n})\)</span> dependence on <span class="math inline">\(n\)</span>? It turns out that the answer is no, and this is related to a surprising phenomenon called the birthday paradox. Suppose there are <span class="math inline">\(23\)</span> students in class. What is the chance that two of them have the same birthday? Naively one might answer that since there are <span class="math inline">\(365\)</span> days in the year, the chance should be roughly <span class="math inline">\(23/365 \approx 6\%\)</span>. The correct answer is over <span class="math inline">\(50\%\)</span>!</p>
<p>Suppose there are <span class="math inline">\(k\)</span> people in the room, and let <span class="math inline">\(A\)</span> be the event that at least two people have the same birthday, and let <span class="math inline">\(\bar{A}\)</span> be the event that no two people have the same birthday. It turns out it is easier to calculate <span class="math inline">\({\mathbb{P}}[{\bar A}]\)</span>, and then <span class="math inline">\({\mathbb{P}}[A] = 1 - {\mathbb{P}}[{\bar A}]\)</span>. Our sample space is of cardinality <span class="math inline">\(|\Omega| = 365^k\)</span>. And the number of sample points such that no two people to have the same birthday can be calculated as follows: there are <span class="math inline">\(365\)</span> choices for the first person, <span class="math inline">\(364\)</span> for the second, …, <span class="math inline">\(365-k+1\)</span> choices for the <span class="math inline">\(k^{\text{th}}\)</span> person, for a total of <span class="math inline">\(365 \times 364 \times \cdots \times (365-k+1)\)</span>. Thus <span class="math display">\[{\mathbb{P}}[{\bar A}] = \frac{{\bar A}|}{|\Omega|} =
\frac{365 \times 364 \times \cdots \times (365-k+1)}{365^k}.\]</span> And <span class="math display">\[{\mathbb{P}}[A] = 1 - \frac{365 \times 364 \times \cdots \times (365-k+1)}{365^k}.\]</span> Substituting <span class="math inline">\(k=23\)</span>, we can check that <span class="math inline">\({\mathbb{P}}[A]\)</span> is over <span class="math inline">\(50\%\)</span>. And with <span class="math inline">\(k=60\)</span> <span class="math inline">\({\mathbb{P}}[A]\)</span> is larger than <span class="math inline">\(99\%\)</span>!</p>
<p>The hashing problem we considered above is a closely related to the birthday problem. Indeed, the birthday problem is the special case of the hashing problem with <span class="math inline">\(365\)</span> bins. The <span class="math inline">\(k = 23\)</span> solution to the birthday problem can be seen as <span class="math inline">\(k\)</span> being roughly <span class="math inline">\(\sqrt{365}\)</span>.</p>
<h1 id="application-2-load-balancing" class="unnumbered">Application 2: Load Balancing</h1>
<p>An important practical issue in distributed computing is how to spread the workload in a distributed system among its processors. Here we investigate an extremely simple scenario that is both fundamental in its own right and also establishes a baseline against which more sophisticated methods should be judged.</p>
<p>Suppose we have <span class="math inline">\(m\)</span> identical jobs and <span class="math inline">\(n\)</span> identical processors. Our task is to assign the jobs to the processors in such a way that no processor is too heavily loaded. Of course, there is a simple optimal solution here: just divide up the jobs as evenly as possible, so that each processor receives either <span class="math inline">\(\lceil m/n \rceil\)</span> or <span class="math inline">\(\lfloor m/n \rfloor\)</span> jobs. However, this solution requires a lot of centralized control, and/or a lot of communication: the workload has to be balanced evenly either by a powerful centralized scheduler that talks to all the processors, or by the exchange of many messages between jobs and processors. This kind of operation is very costly in most distributed systems. The question therefore is: What can we do with little or no overhead in scheduling and communication cost?</p>
<h2 id="back-to-balls-and-bins" class="unnumbered">Back to Balls and Bins</h2>
<p>The first idea that comes to mind here is<span class="math inline">\(\ldots\)</span> balls and bins! In other words, each job simply selects a processor uniformly at random and independently of all others, and goes to that processor. (Make sure you believe that the probability space for this experiment is the same as the one for balls and bins.) This scheme requires no communication. However, presumably it won’t in general achieve an optimal balancing of the load. Let <span class="math inline">\(A_k\)</span> be the event that the load of some processor is at least <span class="math inline">\(k\)</span>. Let <span class="math inline">\(X\)</span> be the maximum loading of any processor under our randomized scheme. Note that <span class="math inline">\(X\)</span> isn’t a fixed number: its value depends on the outcome of our balls and bins experiment.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> As designers or users of this load balancing scheme, here’s one question we might care about:</p>
<dl>
<dt><span><strong>Question:</strong></span></dt>
<dd><p>Find the smallest value <span class="math inline">\(k\)</span> such that <span class="math inline">\({\mathbb{P}}[A_k] \le 1/2\)</span>.</p>
</dd>
</dl>
<p>If we have such a value <span class="math inline">\(k\)</span>, then we’ll know that, with good probability (at least <span class="math inline">\(1/2\)</span>), every processor in our system will have a load at most <span class="math inline">\(k\)</span>. This will give us a good idea about the performance of the system. Of course, as with our hashing application, there’s nothing special about the value <span class="math inline">\(1/2\)</span>; we’re just using this for illustration. As you can check later (if you choose to read the optional section below), essentially the same analysis can be used to find <span class="math inline">\(k\)</span> such that <span class="math inline">\({\mathbb{P}}[A_k]\le 0.05\)</span> (i.e., <span class="math inline">\(95\%\)</span> confidence), or any other value we like. Indeed, we can even find the <span class="math inline">\(k\)</span>’s for several different confidence levels and thus build up a more detailed picture of the behavior of the scheme. To simplify our problem, we’ll also assume from now on that <span class="math inline">\(m=n\)</span> (i.e., the number of jobs is the same as the number of processors). With a bit more work, we could generalize our analysis to other values of <span class="math inline">\(m\)</span>.</p>
<h2 id="applying-the-union-bound" class="unnumbered">Applying the Union Bound</h2>
<p>From Application 1 we know that we get collisions already when <span class="math inline">\(m\approx 1.177\sqrt{n}\)</span>. So when <span class="math inline">\(m=n\)</span> the maximum load will certainly be larger than <span class="math inline">\(1\)</span> (with good probability). But how large will it be? If we try to analyze the maximum load directly, we run into the problem that it depends on the number of jobs at <span><em>every</em></span> processor (or equivalently, the number of balls in every bin). Since the load in one bin depends on those in the others, this becomes very tricky. Instead, what we’ll do is analyze the load in any <span><em>one</em></span> bin, say bin <span class="math inline">\(1\)</span>; this will be fairly easy. Let <span class="math inline">\(A_k(1)\)</span> be the event that the load in bin <span class="math inline">\(1\)</span> is at least <span class="math inline">\(k\)</span>. What we’ll do is find <span class="math inline">\(k\)</span> such that <a name="eq:20"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
   {\mathbb{P}}[A_k(1)] \le {1\over{2n}}.\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(1)</span></span>  Since all the bins are identical, we will then know that, for the same <span class="math inline">\(k\)</span>, <span class="math display">\[{\mathbb{P}}[A_k(i)] \le {1\over{2n}}\qquad \text{for } i=1,2,\ldots,n,\]</span> where <span class="math inline">\(A_k(i)\)</span> is the event that the load in bin <span class="math inline">\(i\)</span> is at least <span class="math inline">\(k\)</span>. But now, since the event <span class="math inline">\(A_k\)</span> is exactly the union of the events <span class="math inline">\(A_k(i)\)</span> (do you see why?), we can use the “Union Bound” from the previous lecture: <span class="math display">\[\begin{aligned}
{\mathbb{P}}[A_k]
  &amp;= {\mathbb{P}}[{\textstyle\bigcup_{i=1}^n A_k(i)}]\\
  &amp;\le n\times{1\over{2n}}\\
  &amp;= {1\over 2}.\end{aligned}\]</span></p>
<p>It’s worth standing back to notice what we did here: we wanted to conclude that <span class="math inline">\({\mathbb{P}}[A_k]\le 1/2\)</span>. We couldn’t analyze <span class="math inline">\(A_k\)</span> directly, but we knew that <span class="math inline">\(A_k=\bigcup_{i=1}^n A_k(i)\)</span>, for much simpler events <span class="math inline">\(A_k(i)\)</span>. Since there are <span class="math inline">\(n\)</span> events <span class="math inline">\(A_k(i)\)</span>, and all have the same probability, it is enough for us to show that <span class="math inline">\({\mathbb{P}}[A_k(i)]\le (2n)^{-1}\)</span>; the union bound then guarantees that <span class="math inline">\({\mathbb{P}}[A_k]\le 1/2\)</span>. This kind of reasoning is very common in applications of probability in Computer Science.</p>
<p>Now all that’s left to do is find <span class="math inline">\(k\)</span> which satisfies Equation <a href="#eq:20">1</a>. That is, we wish to bound the probability that bin <span class="math inline">\(1\)</span> has at least <span class="math inline">\(k\)</span> balls (and find a value of <span class="math inline">\(k\)</span> so that this probability is smaller than <span class="math inline">\((2n)^{-1}\)</span>). We start by observing that for the event <span class="math inline">\(A_k(1)\)</span> to occur (that bin <span class="math inline">\(1\)</span> has at least <span class="math inline">\(k\)</span> balls), there must be some subset <span class="math inline">\(S\)</span> of exactly <span class="math inline">\(k\)</span> balls such that all balls in <span class="math inline">\(S\)</span> ended up in bin <span class="math inline">\(1\)</span>. We can say this more formally as follows: for a subset <span class="math inline">\(S\)</span> (where <span class="math inline">\(|S| = k\)</span>), let <span class="math inline">\(B_S\)</span> be the event that all balls in <span class="math inline">\(S\)</span> land in bin <span class="math inline">\(1\)</span>. Then the event <span class="math inline">\(A_k(1)\)</span> is a subset of the event <span class="math inline">\(\bigcup_{S} B_S\)</span> (where the union is over all sets <span class="math inline">\(S\)</span> of cardinality <span class="math inline">\(k\)</span>). It follows that: <span class="math display">\[{\mathbb{P}}[A_k(1)] \leq \textstyle {\mathbb{P}}[\bigcup_{S} B_S]\]</span> We can use the union bound on <span class="math inline">\({\mathbb{P}}[\bigcup_S B_S]\)</span>: <span class="math display">\[{\textstyle{\mathbb{P}}[\bigcup_S B_S]} \leq \sum\limits_S {\mathbb{P}}[B_S]\]</span> There are <span class="math inline">\({n\choose k}\)</span> sets we are summing over, and for each set <span class="math inline">\(S\)</span>, <span class="math inline">\({\mathbb{P}}[B_S]\)</span> is simple: it is just the probability that <span class="math inline">\(k\)</span> balls land in bin <span class="math inline">\(1\)</span>, or <span class="math inline">\(1/n^k\)</span>. Using these observations and the above equations, we can compute an upper bound on <span class="math inline">\({\mathbb{P}}[A_k(1)]\)</span>: <span class="math display">\[{\mathbb{P}}[A_k(1)]\leq {n\choose k}\frac{1}{n^k}\]</span> Now to satisfy our original goal (Equation <a href="#eq:20">1</a>), we just need to choose <span class="math inline">\(k\)</span> so that <span class="math inline">\({n\choose k}/n^k\leq (2n)^{-1}\)</span>. But we have <span class="math display">\[{n\choose k}\frac{1}{n^k} = \frac{n(n-1)\cdots (n-k+1)}{k!}\frac{1}{n^k} \leq \frac{1}{k!}\]</span> Setting <span class="math inline">\(k! = 2n\)</span>, and simplifying we get that <span class="math inline">\(\left ( k/e \right )^k = 2n\)</span>. Taking logs we get that <span class="math inline">\(k(\ln k - 1) = \ln 2n\)</span>. This gives a value of <span class="math inline">\(k\)</span> of roughly <span class="math inline">\((\ln n)/(\ln \ln n)\)</span>.</p>
<p>If you would like to learn more about how to do this, please refer to the additional section on load balancing below.</p>
<p>Finally, here is one punchline from Application 2. Let’s say the total US population is about 250 million. Suppose we mail 250 million items of junk mail, each one with a random US address. Then (see the optional section below for more details) with probability at least <span class="math inline">\(1/2\)</span>, no one person anywhere will receive more than about a dozen items!</p>
<h1 id="more-about-hashing-optional" class="unnumbered">More about Hashing (Optional)</h1>
<p><em>Please read on only if interested. In this section, we will derive the alternate bound described in the hashing section above.</em></p>
<h2 id="main-idea" class="unnumbered">Main Idea</h2>
<p>Let’s fix the value of <span class="math inline">\(m\)</span> and try to compute <span class="math inline">\({\mathbb{P}}[A]\)</span>. Since our probability space is uniform (each outcome has probability <span class="math inline">\(1/{n^m}\)</span>), it’s enough just to count the number of outcomes in <span class="math inline">\(A\)</span>. In how many ways can we arrange <span class="math inline">\(m\)</span> balls in <span class="math inline">\(n\)</span> bins so that no bin contains more than one ball? Well, this is just the number of ways of choosing <span class="math inline">\(m\)</span> things out of <span class="math inline">\(n\)</span> <span><em>without</em></span> replacement, which as we saw in Note 10 is <span class="math display">\[n\times(n-1)\times(n-2)\times\cdots\times(n-m+2)\times(n-m+1).\]</span> This formula is valid as long as <span class="math inline">\(m\le n\)</span>: if <span class="math inline">\(m&gt;n\)</span> then clearly the answer is zero. From now on, we’ll assume that <span class="math inline">\(m\le n\)</span>.</p>
<p>Now we can calculate the probability of no collision: <a name="eq:1"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[\begin{aligned}
    {\mathbb{P}}[A] &amp;=&amp; {{n(n-1)(n-2)\ldots(n-m+1)}\over{n^m}}\nonumber\\
           &amp;=&amp; {n\over n}\times{{n-1}\over n}\times{{n-2}\over n}\times
                              \cdots\times{{n-m+1}\over n}\nonumber\\
           &amp;=&amp; \Bigl(1-{1\over n}\Bigr)\times\Bigl(1-{2\over n}\Bigr)\times\cdots\times\Bigl(1-{{m-1}\over n}\Bigr).\end{aligned}\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(2)</span></span> </p>
<p>Before going on, let’s pause to observe that we could compute <span class="math inline">\({\mathbb{P}}[A]\)</span> in a different way, as follows. View the probability space as a sequence of choices, one for each ball. For <span class="math inline">\(1\le i\le m\)</span>, let <span class="math inline">\(A_i\)</span> be the event that the <span class="math inline">\(i\)</span>th ball lands in a different bin from balls <span class="math inline">\(1,2,\ldots,i-1\)</span>. Then <span class="math display">\[\begin{aligned}
   {\mathbb{P}}[A]={\mathbb{P}}[{\textstyle\bigcap_{i=1}^n A_i}]
        &amp;=&amp;{\mathbb{P}}[A_1]\times{\mathbb{P}}[A_2\mid A_1]\times{\mathbb{P}}[A_3\mid A_1\cap A_2]\times\cdots\times{\mathbb{P}}[A_m\mid{\textstyle\bigcap_{i=1}^{m-1}A_i}]\nonumber\\
        &amp;=&amp;1\times{{n-1}\over n}\times{{n-2}\over n}\times\cdots\times{{n-m+1}\over n}\nonumber\\
        &amp;=&amp;\Bigl(1-{1\over n}\Bigr)\times\Bigl(1-{2\over n}\Bigr)\times\cdots\times\Bigl(1-{{m-1}\over n}\Bigr).\nonumber\end{aligned}\]</span> Fortunately, we get the same answer as before! [You should make sure you see how we obtained the conditional probabilities in the second line above. For example, <span class="math inline">\({\mathbb{P}}[A_3\mid A_1\cap A_2]\)</span> is the probability that the third ball lands in a different bin from the first two balls, <span><em>given that</em></span> those two balls also landed in different bins. This means that the third ball has <span class="math inline">\(n-2\)</span> possible bin choices out of a total of <span class="math inline">\(n\)</span>.]</p>
<p>Essentially, we are now done with our problem: Equation <a href="#eq:1">2</a> gives an exact formula for the probability of no collision when <span class="math inline">\(m\)</span> keys are hashed. All we need to do now is plug values <span class="math inline">\(m=1,2,3,\ldots\)</span> into Equation <a href="#eq:1">2</a> until we find that <span class="math inline">\({\mathbb{P}}[A]\)</span> drops below <span class="math inline">\(1/2\)</span>. The corresponding value of <span class="math inline">\(m\)</span> (minus <span class="math inline">\(1\)</span>) is what we want.</p>
<p>We can actually make this bound much more useful by turning it around, as we will do below. We will derive an equation which tells us the value of <span class="math inline">\(m\)</span> at which <span class="math inline">\({\mathbb{P}}[A]\)</span> drops below <span class="math inline">\(1/2\)</span>. It turns out that if <span class="math inline">\(m\)</span> is smaller than approximately <span class="math inline">\(1.177\sqrt{n}\)</span>, the probability of a collision will be less than <span class="math inline">\(1/2\)</span>.</p>
<h2 id="further-simplification" class="unnumbered">Further Simplification</h2>
<p>The bound we gave above (for the largest number <span class="math inline">\(m\)</span> of keys we can store before the probability of a collision reaches <span class="math inline">\(1/2\)</span>) is not really satisfactory: it would be much more useful to have a formula that gives the “critical” value of <span class="math inline">\(m\)</span> directly, rather than having to compute <span class="math inline">\({\mathbb{P}}[A]\)</span> for <span class="math inline">\(m=1,2,3,\ldots\)</span>. Note that we would have to do this computation separately for each different value of <span class="math inline">\(n\)</span> we are interested in: i.e., whenever we change the size of our hash table.</p>
<p>So what remains is to “turn Equation <a href="#eq:1">2</a> around”, so that it tells us the value of <span class="math inline">\(m\)</span> at which <span class="math inline">\({\mathbb{P}}[A]\)</span> drops below <span class="math inline">\(1/2\)</span>. To do this, let’s take logs: this is a good thing to do because it turns the product into a sum, which is easier to handle. We get <a name="eq:2"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
   \ln({\mathbb{P}}[A]) = \ln\Bigl(1-{1\over n}\Bigr) + 
                 \ln\Bigl(1-{2\over n}\Bigr) + \cdots +
                 \ln\Bigl(1-{{m-1}\over n}\Bigr),\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(3)</span></span>  where “<span class="math inline">\(\ln\)</span>” denotes natural (base <span class="math inline">\(e\)</span>) logarithm. Now we can make use of a standard approximation for logarithms: namely, if <span class="math inline">\(x\)</span> is small then <span class="math inline">\(\ln(1-x)\approx -x\)</span>. This comes from the Taylor series expansion <span class="math display">\[\ln(1-x) = -x -{{x^2}\over 2} -{{x^3}\over 3} - \cdots.\]</span> So by replacing <span class="math inline">\(\ln(1-x)\)</span> by <span class="math inline">\(-x\)</span> we are making an error of at most <span class="math inline">\(x^2/2+x^3/3+\cdots\)</span>, which is at most <span class="math inline">\(2x^2\)</span> when <span class="math inline">\(x\le 1/2\)</span>. In other words, we have <span class="math display">\[-x \ge \ln(1-x) \ge -x -2x^2.\]</span> And if <span class="math inline">\(x\)</span> is small then the error term <span class="math inline">\(2x^2\)</span> will be much smaller than the main term <span class="math inline">\(-x\)</span>. Rather than carry around the error term <span class="math inline">\(2x^2\)</span> everywhere, in what follows we’ll just write <span class="math inline">\(\ln(1-x)\approx -x\)</span>, secure in the knowledge that we could make this approximation precise if necessary.</p>
<p>Now let’s plug this approximation into Equation <a href="#eq:2">3</a>: <a name="eq:3"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[\begin{aligned}
   \ln({\mathbb{P}}[A]) &amp;\approx&amp; -{1\over n} -{2\over n} -{3\over n} -\ldots
                                              -{{m-1}\over n}\nonumber\\
               &amp;=&amp;       -{1\over n}\sum_{i=1}^{m-1} i\nonumber\\
               &amp;=&amp;       -{{m(m-1)}\over{2n}}\nonumber\\
               &amp;\approx&amp; -{{m^2}\over{2n}}.\end{aligned}\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(4)</span></span>  Note that we’ve used the approximation for <span class="math inline">\(\ln(1-x)\)</span> with <span class="math inline">\(x=1/n,2/n,3/n,\ldots,(m-1)/n\)</span>. So our approximation should be good provided all these are small, i.e., provided <span class="math inline">\(n\)</span> is fairly big and <span class="math inline">\(m\)</span> is quite a bit smaller than <span class="math inline">\(n\)</span>. Once we’re done, we’ll see that the approximation is actually pretty good even for modest sizes of <span class="math inline">\(n\)</span>.</p>
<p>Now we can undo the logs in Equation <a href="#eq:3">4</a> to get our expression for <span class="math inline">\({\mathbb{P}}[A]\)</span>: <span class="math display">\[{\mathbb{P}}[A]\approx{\rm e}^{-m^2/(2n)}.\]</span> The final step is to figure out for what value of <span class="math inline">\(m\)</span> this probability becomes <span class="math inline">\(1/2\)</span>. So we want the largest <span class="math inline">\(m\)</span> such that <span class="math inline">\({\rm e}^{-m^2/(2n)}\ge 1/2\)</span>. This means we must have <span class="math display">\[\begin{aligned}
   -{{m^2}\over{2n}}&amp;\ge&amp;\ln \frac{1}{2} = -\ln 2,\\
         &amp;&amp;\text{or equivalently}\nonumber\\
                    m&amp;\le&amp;\sqrt{(2\ln 2)n}\approx 1.177\sqrt{n}.\end{aligned}\]</span> So the bottom line is that we can hash approximately <span class="math inline">\(m = \lfloor 1.177 \sqrt{n} \rfloor\)</span> before the probability of a collision reaches <span class="math inline">\(1/2\)</span>.</p>
<p>Recall that our calculation was only approximate; so we should go back and get a feel for how much error we made. We can do this by using Equation <a href="#eq:1">2</a> to compute the exact value <span class="math inline">\(m=m_0\)</span> at which <span class="math inline">\({\mathbb{P}}[A]\)</span> drops below <span class="math inline">\(1/2\)</span>, for a few sample values of <span class="math inline">\(n\)</span>. Then we can compare these values with our estimate <span class="math inline">\(m=1.177\sqrt{n}\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(n\)</span></th>
<th align="center"><span class="math inline">\(10\)</span></th>
<th align="center"><span class="math inline">\(20\)</span></th>
<th align="center"><span class="math inline">\(50\)</span></th>
<th align="center"><span class="math inline">\(100\)</span></th>
<th align="center"><span class="math inline">\(200\)</span></th>
<th align="center"><span class="math inline">\(365\)</span></th>
<th align="center"><span class="math inline">\(500\)</span></th>
<th align="center"><span class="math inline">\(1000\)</span></th>
<th align="center"><span class="math inline">\(10^4\)</span></th>
<th align="center"><span class="math inline">\(10^5\)</span></th>
<th align="center"><span class="math inline">\(10^6\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><span class="math inline">\(1.177\sqrt{n}\)</span></td>
<td align="center"><span class="math inline">\(3.7\)</span></td>
<td align="center"><span class="math inline">\(5.3\)</span></td>
<td align="center"><span class="math inline">\(8.3\)</span></td>
<td align="center"><span class="math inline">\(11.8\)</span></td>
<td align="center"><span class="math inline">\(16.6\)</span></td>
<td align="center"><span class="math inline">\(22.5\)</span></td>
<td align="center"><span class="math inline">\(26.3\)</span></td>
<td align="center"><span class="math inline">\(37.3\)</span></td>
<td align="center"><span class="math inline">\(118\)</span></td>
<td align="center"><span class="math inline">\(372\)</span></td>
<td align="center"><span class="math inline">\(1177\)</span></td>
</tr>
<tr class="even">
<td align="right">exact <span class="math inline">\(m_0\)</span></td>
<td align="center"><span class="math inline">\(4\)</span></td>
<td align="center"><span class="math inline">\(5\)</span></td>
<td align="center"><span class="math inline">\(8\)</span></td>
<td align="center"><span class="math inline">\(12\)</span></td>
<td align="center"><span class="math inline">\(16\)</span></td>
<td align="center"><span class="math inline">\(22\)</span></td>
<td align="center"><span class="math inline">\(26\)</span></td>
<td align="center"><span class="math inline">\(37\)</span></td>
<td align="center"><span class="math inline">\(118\)</span></td>
<td align="center"><span class="math inline">\(372\)</span></td>
<td align="center"><span class="math inline">\(1177\)</span></td>
</tr>
</tbody>
</table>
<p>From the table, we see that our approximation is very good even for small values of <span class="math inline">\(n\)</span>. When <span class="math inline">\(n\)</span> is large, the error in the approximation becomes negligible.</p>
<h2 id="why-half" class="unnumbered">Why <span class="math inline">\(1/2\)</span>?</h2>
<p>As mentioned above, we could consider values other than <span class="math inline">\(1/2\)</span>. What we did above was to (approximately) compute <span class="math inline">\({\mathbb{P}}[A]\)</span> (the probability of no collision) as a function of <span class="math inline">\(m\)</span>, and then find the largest value of <span class="math inline">\(m\)</span> for which our estimate is smaller than <span class="math inline">\(1/2\)</span>. If instead we were interested in keeping the collision probability below (say) <span class="math inline">\(0.05\)</span> (<span class="math inline">\(=5\%\)</span>), we could derive that we could hash at most <span class="math inline">\(m=\sqrt{(2\ln(20/19)) n}\approx 0.32\sqrt{n}\)</span> keys. Of course, this number is a bit smaller than before because our collision probability is now smaller. But no matter what “confidence” probability we specify, our critical value of <span class="math inline">\(m\)</span> will always be <span class="math inline">\(c\sqrt{n}\)</span> for some constant <span class="math inline">\(c\)</span> (which depends on the confidence).</p>
<h1 id="more-about-load-balancing-optional" class="unnumbered">More about Load Balancing (Optional)</h1>
<p>In this section, we’ll come up with a slightly tighter bound for <span class="math inline">\(k\)</span> and we will also show how to choose <span class="math inline">\(k\)</span> so that the probability of an overloaded processor is less than <span class="math inline">\(1/2\)</span>.</p>
<p>We’ll start with an alternate calculation of <span class="math inline">\({\mathbb{P}}[A_k(1)]\)</span>. Let <span class="math inline">\(C_j(1)\)</span> be the event that the number of balls in bin <span class="math inline">\(1\)</span> is exactly <span class="math inline">\(j\)</span>. It’s not hard to write down an <em>exact</em> expression for <span class="math inline">\({\mathbb{P}}[C_j(1)]\)</span>: <a name="eq:21"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
   {\mathbb{P}}[C_j(1)] = {n\choose j} \left({1\over n}\right)^j
                             \left(1-{1\over n}\right)^{n-j}.\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(5)</span></span>  This can be seen by viewing each ball as a biased coin toss: Heads corresponds to the ball landing in bin <span class="math inline">\(1\)</span>, Tails to all other outcomes. So the Heads probability is <span class="math inline">\(1/n\)</span>; and all coin tosses are (mutually) independent. As we saw in earlier lectures, Equation <a href="#eq:21">5</a> gives the probability of exactly <span class="math inline">\(j\)</span> Heads in <span class="math inline">\(n\)</span> tosses.</p>
<p>Thus we have <a name="eq:22"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
   {\mathbb{P}}[A_k(1)] = \sum_{j=k}^n {\mathbb{P}}[C_j(1)] 
                 = \sum_{j=k}^n{n\choose j} \left({1\over n}\right)^j\left(1-{1\over n}\right)^{n-j}.\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(6)</span></span>  Now in some sense we are done: we could try plugging values <span class="math inline">\(k=1,2,\ldots\)</span> into Equation <a href="#eq:22">6</a> until the probability drops below <span class="math inline">\((2n)^{-1}\)</span>. However, it is also possible to massage Equation <a href="#eq:22">6</a> into a cleaner form from which we can read off the value of <span class="math inline">\(k\)</span> more directly. We will need to do a few calculations and approximations: <a name="eq:23"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[\begin{aligned}
{\mathbb{P}}[A_k(1)] &amp;= \sum_{j=k}^n{n\choose j} \left({1\over n}\right)^j\left(1-{1\over n}\right)^{n-j}\nonumber\\
              &amp;\le \sum_{j=k}^n \left({ne\over j}\right)^j\left({1\over n}\right)^j\nonumber\\
              &amp;= \sum_{j=k}^n \left({e\over j}\right)^j\end{aligned}\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(7)</span></span>  In the second line here, we used the standard approximation<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <span class="math inline">\((n/j)^j\le{n\choose j}\le (ne/j)^j\)</span>. Also, we tossed away the <span class="math inline">\((1-1/n)^{n-j}\)</span> term, which is permissible because doing so can only increase the value of the sum (i.e., since <span class="math inline">\((1-1/n)^{n-j} \le 1\)</span>). It will turn out that we didn’t lose too much by applying these bounds.</p>
<p>Now we’re already down to a much cleaner form in Equation <a href="#eq:23">7</a>. To finish up, we just need to sum the series. Again, we’ll make an approximation to simplify our task, and hope that it doesn’t cost us too much. The terms in the series in Equation <a href="#eq:23">7</a> go down at each step by a factor of at least <span class="math inline">\(e/k\)</span>. So we can bound the series by a <span><em>geometric</em></span> series, which is easy to sum: <a name="eq:24"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
     \sum_{j=k}^n \left({e\over j}\right)^j
            \le\left({e \over k}\right)^k
                \left( 1+{e\over k}+\left({e\over k}\right)^2+\cdots\right)
            \le 2\left({e\over k}\right)^k,\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(8)</span></span>  where the second inequality holds provided we assume that <span class="math inline">\(k\ge 2e\)</span> (which it will be, as we shall see in a moment).</p>
<p>So what we have now shown is the following: <a name="eq:25"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
   {\mathbb{P}}[A_k(1)] \le 2\left({e\over k}\right)^k\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(9)</span></span>  (provided <span class="math inline">\(k\ge 2e\)</span>). Note that, even though we have made a few approximations, Equation <a href="#eq:25">9</a> is completely valid: all our approximations were “<span class="math inline">\(\le\)</span>”, so we always have an <span><em>upper</em></span> bound on <span class="math inline">\({\mathbb{P}}[X_1\ge k]\)</span>. [You should go back through all the steps and check this.]</p>
<p>Recall from Equation <a href="#eq:20">1</a> that our goal is to make the probability in Equation <a href="#eq:25">9</a> less than <span class="math inline">\((2n)^{-1}\)</span>. We can ensure this by choosing <span class="math inline">\(k\)</span> so that <a name="eq:26"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
  \left({e\over k}\right)^k \le {1\over{4n}}.\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(10)</span></span>  Now we are in good shape: given any value <span class="math inline">\(n\)</span> for the number of jobs/processors, we just need to find the smallest value <span class="math inline">\(k=k_0\)</span> that satisfies Equation <a href="#eq:26">10</a>. We will then know that, with probability at least <span class="math inline">\(1/2\)</span>, the maximum load on any processor is at most <span class="math inline">\(k_0\)</span>. The table below shows the values of <span class="math inline">\(k_0\)</span> for some sample values of <span class="math inline">\(n\)</span>. It is recommended that you perform the experiment and compare these values of <span class="math inline">\(k_0\)</span> with what happens in practice.</p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(n\)</span></th>
<th align="center"><span class="math inline">\(10\)</span></th>
<th align="center"><span class="math inline">\(20\)</span></th>
<th align="center"><span class="math inline">\(50\)</span></th>
<th align="center"><span class="math inline">\(100\)</span></th>
<th align="center"><span class="math inline">\(500\)</span></th>
<th align="center"><span class="math inline">\(1000\)</span></th>
<th align="center"><span class="math inline">\(10^4\)</span></th>
<th align="center"><span class="math inline">\(10^5\)</span></th>
<th align="center"><span class="math inline">\(10^6\)</span></th>
<th align="center"><span class="math inline">\(10^7\)</span></th>
<th align="center"><span class="math inline">\(10^8\)</span></th>
<th align="center"><span class="math inline">\(10^{15}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">exact <span class="math inline">\(k_0\)</span></td>
<td align="center"><span class="math inline">\(6\)</span></td>
<td align="center"><span class="math inline">\(6\)</span></td>
<td align="center"><span class="math inline">\(7\)</span></td>
<td align="center"><span class="math inline">\(7\)</span></td>
<td align="center"><span class="math inline">\(8\)</span></td>
<td align="center"><span class="math inline">\(8\)</span></td>
<td align="center"><span class="math inline">\(9\)</span></td>
<td align="center"><span class="math inline">\(10\)</span></td>
<td align="center"><span class="math inline">\(11\)</span></td>
<td align="center"><span class="math inline">\(12\)</span></td>
<td align="center"><span class="math inline">\(13\)</span></td>
<td align="center"><span class="math inline">\(19\)</span></td>
</tr>
<tr class="even">
<td align="right"><span class="math inline">\(\ln(4n)\)</span></td>
<td align="center"><span class="math inline">\(3.7\)</span></td>
<td align="center"><span class="math inline">\(4.4\)</span></td>
<td align="center"><span class="math inline">\(5.3\)</span></td>
<td align="center"><span class="math inline">\(6.0\)</span></td>
<td align="center"><span class="math inline">\(7.6\)</span></td>
<td align="center"><span class="math inline">\(8.3\)</span></td>
<td align="center"><span class="math inline">\(10.6\)</span></td>
<td align="center"><span class="math inline">\(13.9\)</span></td>
<td align="center"><span class="math inline">\(15.2\)</span></td>
<td align="center"><span class="math inline">\(17.5\)</span></td>
<td align="center"><span class="math inline">\(19.8\)</span></td>
<td align="center"><span class="math inline">\(36\)</span></td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\((2 \ln n)/(\ln \ln n)\)</span></td>
<td align="center"><span class="math inline">\(5.6\)</span></td>
<td align="center"><span class="math inline">\(5.4\)</span></td>
<td align="center"><span class="math inline">\(5.8\)</span></td>
<td align="center"><span class="math inline">\(6.0\)</span></td>
<td align="center"><span class="math inline">\(6.8\)</span></td>
<td align="center"><span class="math inline">\(7.2\)</span></td>
<td align="center"><span class="math inline">\(8.2\)</span></td>
<td align="center"><span class="math inline">\(9.4\)</span></td>
<td align="center"><span class="math inline">\(10.6\)</span></td>
<td align="center"><span class="math inline">\(11.6\)</span></td>
<td align="center"><span class="math inline">\(12.6\)</span></td>
<td align="center"><span class="math inline">\(20\)</span></td>
</tr>
</tbody>
</table>
<p>Can we come up with a formula for <span class="math inline">\(k_0\)</span> as a function of <span class="math inline">\(n\)</span> (as we did for the hashing problem)? Well, let’s take logs in Equation <a href="#eq:26">10</a>: <a name="eq:27"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
   k(\ln k -1) \ge \ln(4n).\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(11)</span></span>  From this, we might guess that <span class="math inline">\(k=\ln(4n)\)</span> is a good value for <span class="math inline">\(k_0\)</span>. Plugging in this value of <span class="math inline">\(k\)</span> makes the left-hand side of Equation <a href="#eq:27">11</a> equal to <span class="math inline">\(\ln(4n)(\ln\ln(4n) -1)\)</span>, which is certainly bigger than <span class="math inline">\(\ln(4n)\)</span> provided <span class="math inline">\(\ln\ln(4n)\ge 2\)</span>, i.e., <span class="math inline">\(n\ge e^{e^2}/4 \approx 405\)</span>. So for <span class="math inline">\(n\ge 405\)</span> we can claim that the maximum load is (with probability at least <span class="math inline">\(1/2\)</span>) no larger than <span class="math inline">\(\ln(4n)\)</span>. The table above plots the values of <span class="math inline">\(\ln(4n)\)</span> for comparison with <span class="math inline">\(k_0\)</span>. As expected, the estimate is quite good for small <span class="math inline">\(n\)</span>, but becomes rather pessimistic when <span class="math inline">\(n\)</span> is large.</p>
<p>For large <span class="math inline">\(n\)</span> we can do better as follows. If we plug the value <span class="math inline">\(k=(\ln n)/(\ln \ln n)\)</span> into the left-hand side of Equation <a href="#eq:27">11</a>, it becomes <a name="eq:28"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
   {{\ln n}\over{\ln\ln n}}\left(\ln\ln n - \ln\ln\ln n -1\right)
            = \ln n\left(1 - {{\ln\ln\ln n + 1}\over{\ln\ln n}}\right).\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(12)</span></span>  Now when <span class="math inline">\(n\)</span> is large this is <span><em>just barely</em></span> smaller than the right-hand side, <span class="math inline">\(\ln(4n)\)</span>. Why? Because the second term inside the parentheses goes to zero as <span class="math inline">\(n\to\infty\)</span>,<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> and because <span class="math inline">\(\ln(4n)=\ln n + \ln 4\)</span>, which is very close to <span class="math inline">\(\ln n\)</span> when <span class="math inline">\(n\)</span> is large (since <span class="math inline">\(\ln 4\)</span> is a fixed small constant). So we can conclude that, for large values of <span class="math inline">\(n\)</span>, the quantity <span class="math inline">\((\ln n)/(\ln \ln n)\)</span> should be a pretty good estimate of <span class="math inline">\(k_0\)</span>. Actually for this estimate to become good <span class="math inline">\(n\)</span> has to be (literally) astronomically large. For more civilized values of <span class="math inline">\(n\)</span>, we get a better estimate by taking <span class="math inline">\(k=(2\ln n)/(\ln \ln n)\)</span>. The extra factor of <span class="math inline">\(2\)</span> helps to wipe out the lower order terms (i.e., the second term in the parenthesis in Equation <a href="#eq:28">12</a> and the <span class="math inline">\(\ln 4\)</span>) more quickly. The table above also shows the behavior of this estimate for various values of <span class="math inline">\(n\)</span>.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>In fact, <span class="math inline">\(X\)</span> is called a <em>random variable</em>: we’ll define this properly in the next lecture.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Computer scientists and mathematicians carry around a little bag of tricks for replacing complicated expressions like <span class="math inline">\({n\choose j}\)</span> with simpler approximations. This is just one of these. It isn’t too hard to prove the lower bound, i.e., that <span class="math inline">\({n\choose j}\ge(n/j)^j\)</span>. The upper bound is a bit trickier, and makes use of another approximation for <span class="math inline">\(n!\)</span> known as <span><em>Stirling’s approximation</em></span>, which implies that <span class="math inline">\(j!\ge (j/e)^j\)</span>. We won’t discuss the details here.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>To see this, note that it is of the form <span class="math inline">\((\ln z + 1)/z\)</span> where <span class="math inline">\(z=\ln\ln n\)</span>, and of course <span class="math inline">\((\ln z + 1)/z \to 0\)</span> as <span class="math inline">\(z\to\infty\)</span>.<a href="#fnref3">↩</a></p></li>
</ol>
</div>
</article>
</body>

<!-- Mirrored from www.eecs70.org/static/notes/n15.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 17 May 2018 00:40:16 GMT -->
</html>
